---
title: "Understanding the Statistical Distributions"
author: "AbdulHafiz Abba"
date: "`r Sys.Date()`"
output: 
  cleanrmd::html_document_clean:
    theme: NULL
#output:
#  html_document:
#    theme: united 
#    toc: true
#    toc_float: true
#    df_print: paged
  pdf_document: default

runtime: shiny
---

## **Statistical Distributions**
In statistics, there are many different probability distributions that are used to model and describe various types of data and random phenomena. These distributions can be broadly categorized into two main types: discrete and continuous distributions. Here are some of the most commonly encountered probability distributions in each category:

## **Discrete Probability Distributions**:

### 1. Bernoulli Distribution:
Models a binary outcome (e.g., success/failure) with a single parameter p representing the probability of success.

Imagine you're playing a really simple game, like flipping a coin. In this game, there are only two possible outcomes: you can either win or lose. Let's call winning a "success" and losing a "failure."

Now, let's say you want to know the chances of winning (getting a success) in this game. The Bernoulli Distribution helps you figure that out.

It's like asking, "What's the probability that I'll win when I play this game once?" The Bernoulli Distribution gives you a way to calculate that probability.

So, if you're flipping a fair coin, you have a 50% chance of winning (getting a head) and a 50% chance of losing (getting a tail). In this case, the Bernoulli Distribution is pretty straightforward. It's like a simple tool for finding the probability of success in a basic "win or lose" situation.

\[ 
\begin{equation}
P(X = x) = p^x \cdot (1 - p)^{1-x}
\end{equation}
\]
```{r echo=FALSE}
library(flexdashboard)
library(shiny)
library(ggplot2)
library(knitr)
# Define the user interface (UI)
ui <- fluidPage(
  titlePanel("Bernoulli Distribution"),
  sidebarLayout(
    sidebarPanel(
      numericInput("p", "Probability of Success (p):", min = 0, max = 1, step = 0.01, value = 0.5),
      actionButton("update", "Update Plot")
    ),
    mainPanel(
      plotOutput("bernoulliPlot")
    )
  )
)

# Define the server logic
server <- function(input, output) {
  
  # Create a reactive expression for the Bernoulli distribution
  bernoulliDist <- reactive({
    p <- input$p
    x <- c(0, 1)
    probabilities <- c(1 - p, p)
    data.frame(x, probabilities)
  })
  
  # Create the Bernoulli distribution plot
  output$bernoulliPlot <- renderPlot({
    df <- bernoulliDist()
    
    ggplot(df, aes(x = factor(x), y = probabilities)) +
      geom_bar(stat = "identity", fill = "blue", width = 0.5) +
      labs(title = "Bernoulli Distribution",
           x = "Outcome",
           y = "Probability") +
      theme_minimal() +
      ylim(0, 1)
  })
  
  # Observe the "Update Plot" button click and update the plot
  observeEvent(input$update, {
    output$bernoulliPlot <- renderPlot({
      df <- bernoulliDist()
      
      ggplot(df, aes(x = factor(x), y = probabilities)) +
        geom_bar(stat = "identity", fill = "blue", width = 0.5) +
        labs(title = "Bernoulli Distribution",
             x = "Outcome",
             y = "Probability") +
        theme_minimal() +
        ylim(0, 1)
    })
  })
}

# Run the Shiny app
shinyApp(ui = ui, server = server)

```


```{r eval=FALSE, include=FALSE}
# Set the seed for reproducibility
set.seed(123)

# Number of trials (sample size)
n <- 1000

# Probability of success (e.g., getting a "1" or "success")
p <- 0.3

# Generate random samples from a Bernoulli distribution
bernoulli_samples <- rbinom(n, size = 1, prob = p)

# Display a histogram to visualize the distribution
hist(bernoulli_samples, breaks = 2, main = "Bernoulli Distribution",
     xlab = "Outcome (0 or 1)", ylab = "Frequency", col = "lightblue")

# Add labels for the two outcomes
axis(1, at = c(0, 1), labels = c("Failure (0)", "Success (1)"))

```

```{r eval=FALSE, include=FALSE}
# Set the seed for reproducibility
set.seed(123)

# Parameters for the Bernoulli distribution
p <- 0.3  # Probability of success (e.g., getting a "1")

# Number of trials to simulate
num_trials <- 1000

# Number of Bernoulli trials in each sample
sample_size <- 100

# Initialize an empty vector to store sample means
sample_means <- numeric(num_trials)

# Simulate the CLT by repeating the sampling process many times
for (i in 1:num_trials) {
  # Simulate a sample of Bernoulli trials
  sample <- rbinom(sample_size, size = 1, prob = p)
  
  # Calculate the sample mean
  sample_means[i] <- mean(sample)
}

# Plot the sampling distribution of the sample mean
hist(sample_means, breaks = 30, main = "Sampling Distribution of Sample Mean (Bernoulli)",
     xlab = "Sample Mean", ylab = "Frequency", col = "lightblue")

# Add a vertical line at the population mean (expected value)
abline(v = p, col = "red", lwd = 2)

# Add a legend
legend("topright", legend = c("Population Mean", "Sample Mean"), col = c("red", "black"), lwd = 2)

```


### 2. Binomial Distribution: 

Represents the number of successes in a fixed number of independent Bernoulli trials.
**Binomial Distribution in Simple Terms:**

Imagine you're flipping a fair coin, and you want to know the probability of getting a certain number of heads in a fixed number of flips. That's where the binomial distribution comes in.

It's like asking, "What are the chances of getting exactly 3 heads if I flip this coin 10 times?" Or, "What's the probability of getting 7 heads in 20 flips?" The binomial distribution helps you answer these questions.

In simpler words, it's a math tool that helps you figure out the probabilities of getting a specific number of "successes" (like heads) in a set number of tries (like coin flips), assuming each try is independent and has the same probability of success.

$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$


- \(P(X = k)\) represents the probability of getting exactly \(k\) successes.
- \(n\) is the total number of trials or attempts.
- \(k\) is the number of successes you want to find the probability for.
- \(p\) is the probability of success in a single trial.
- \(\binom{n}{k}\) represents the binomial coefficient, which calculates the number of ways to choose \(k\) successes out of \(n\) trials.

You can use this formula to calculate the probability of achieving a specific number of successes in a given number of trials with a known probability of success for each trial.

**Graph of Binomial Distribution**
```{r echo=FALSE}
library(shiny)
library(ggplot2)

ui <- fluidPage(
  titlePanel("Binomial Distribution Plotter"),
  sidebarLayout(
    sidebarPanel(
      numericInput("n", "Number of Trials (n):", value = 10),
      sliderInput("p", "Success Probability (p):", min = 0, max = 1, value = 0.5, step = 0.01),
      actionButton("update", "Update Plot")
    ),
    mainPanel(
      plotOutput("binomialPlot")
    )
  )
)

server <- function(input, output) {
  binomialDist <- reactive({
    n <- input$n
    p <- input$p
    x <- seq(0, n, by = 1)
    dbinom(x, size = n, prob = p)
  })
  
  output$binomialPlot <- renderPlot({
    x <- seq(0, input$n, by = 1)
    plot(x, binomialDist(), type = "h", lwd = 10,
         main = "Binomial Distribution",
         xlab = "Number of Successes",
         ylab = "Probability",
         col = "blue",
         ylim = c(0, max(binomialDist()) + 0.1))
  })
  
  observeEvent(input$update, {
    output$binomialPlot <- renderPlot({
      x <- seq(0, input$n, by = 1)
      plot(x, binomialDist(), type = "h", lwd = 10,
           main = "Binomial Distribution",
           xlab = "Number of Successes",
           ylab = "Probability",
           col = "blue",
           ylim = c(0, max(binomialDist()) + 0.1))
    })
  })
}

shinyApp(ui = ui, server = server)

```

```{r eval=FALSE, include=FALSE}
# Parameters for the binomial distribution
n <- 50  # Number of trials
p <- 0.5 # Probability of success (e.g., getting heads in a coin flip)

# Calculate probabilities for each number of successes (0 to n)
x <- 0:n
probabilities <- dbinom(x, size = n, prob = p)

# Create a bar plot of the binomial distribution
barplot(probabilities, names.arg = x, xlab = "Number of Successes",
        ylab = "Probability", main = "Binomial Distribution (n=10, p=0.5)",
        col = "blue", border = "black")

```
**To demonstrate the Central Limit Theorem (CLT)** in the context of a binomial distribution, you can simulate the distribution of sample means for a large number of random samples and observe how it approximates a normal distribution.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(flexdashboard)
library(shiny)

# Define the user interface
ui <- fluidPage(
  titlePanel("Binomial Distribution Shiny App"),
  sidebarLayout(
    sidebarPanel(
      numericInput("n", "Number of Trials (n):", value = 10),
      sliderInput("p", "Success Probability (p):", min = 0, max = 1, value = 0.5, step = 0.01),
      actionButton("update", "Update Plot")
    ),
    mainPanel(
      plotOutput("binomialPlot")
    )
  )
)

# Define the server logic
server <- function(input, output) {
  
  # Create a reactive expression for the Binomial distribution
  binomialDist <- reactive({
    n <- input$n
    p <- input$p
    x <- seq(0, n, by = 1)
    dbinom(x, size = n, prob = p)
  })
  
  # Create the Binomial distribution plot
  output$binomialPlot <- renderPlot({
    x <- seq(0, input$n, by = 1)
    plot(x, binomialDist(), type = "h", lwd = 10,
         main = "Binomial Distribution",
         xlab = "Number of Successes",
         ylab = "Probability",
         col = "blue",
         ylim = c(0, max(binomialDist()) + 0.1))
  })
  
  # Observe the "Update Plot" button click and update the plot
  observeEvent(input$update, {
    output$binomialPlot <- renderPlot({
      x <- seq(0, input$n, by = 1)
      plot(x, binomialDist(), type = "h", lwd = 10,
           main = "Binomial Distribution",
           xlab = "Number of Successes",
           ylab = "Probability",
           col = "blue",
           ylim = c(0, max(binomialDist()) + 0.1))
    })
  })
}

# Create the Shiny app
shinyApp(ui = ui, server = server)

```


### 3. Poisson Distribution:
Describes the number of events occurring in a fixed interval of time or space, assuming a known average rate.

Think of the Poisson Distribution as a way to predict how often something rare happens. It's like counting how many cars pass by a quiet street in an hour. Most of the time, you might see just a few cars, but occasionally, there might be a burst of cars passing by. The Poisson Distribution helps us figure out the chances of these bursts.

In simple terms, it's used when we have events that happen randomly, but they're rare, and we want to know how often they occur in a specific amount of time or space.


The probability mass function of the Poisson Distribution is given by:

\[
P(X = k) = \frac{e^{-\lambda} \cdot \lambda^k}{k!}
\]

Where:
- \(P(X = k)\) is the probability of observing \(k\) events.
- \(e\) is the mathematical constant (approximately 2.71828).
- \(\lambda\) (lambda) is the average rate of events happening in the given time or space.
- \(k\) is the number of events we want to find the probability for.
- \(k!\) is the factorial of \(k\), which means multiplying all positive whole numbers from 1 to \(k\).

This formula helps us calculate the likelihood of seeing a specific number of rare events when we know how often they usually happen on average (\(\lambda\)).

```{r echo=FALSE}
# Load necessary libraries
library(shiny)
library(ggplot2)

# Define the UI for the Shiny app
ui <- fluidPage(
  titlePanel("Poisson Distribution Visualization"),
  
  # Sidebar layout
  sidebarLayout(
    sidebarPanel(
      # User inputs
      numericInput("lambda", "Average Rate (λ):", value = 5, min = 1, max = 20),
      numericInput("k", "Number of Events (k):", value = 5, min = 1, max = 20)
    ),
    
    mainPanel(
      # Display the Poisson distribution plot
      plotOutput("poissonPlot")
    )
  )
)

# Define the server logic
server <- function(input, output) {
  # Create the Poisson distribution plot
  output$poissonPlot <- renderPlot({
    lambda <- input$lambda
    k <- input$k
    
    # Generate data for the Poisson distribution
    x <- 0:20  # Possible values of k
    
    # Calculate the Poisson probability for each value of k
    poisson_probs <- dpois(x, lambda)
    
    # Create a data frame for the plot
    df <- data.frame(x, poisson_probs)
    
    # Plot the Poisson distribution
    ggplot(df, aes(x, poisson_probs)) +
      geom_bar(stat = "identity", fill = "blue", width = 0.5) +
      labs(title = "Poisson Distribution",
           x = "Number of Events (k)",
           y = "Probability") +
      theme_minimal()
  })
}

# Run the Shiny app
shinyApp(ui, server)

```


### 4. Geometric Distribution:
Models the number of trials needed to achieve the first success in a series of Bernoulli trials.

### 5. Hypergeometric Distribution:
Used for sampling without replacement, such as drawing items from a finite population without replacement.

### 6. Negative Binomial Distribution:
Represents the number of trials required for a given number of successes in a series of Bernoulli trials.

### 7. Multinomial Distribution:
Generalization of the binomial distribution for more than two categories.

## **Continuous Probability Distributions**:

### 9. Normal (Gaussian) Distribution:
Often referred to as the bell curve, it's used to model many natural phenomena due to its symmetry and central limit theorem properties.

### 10. Uniform Distribution:
All values within an interval are equally likely.

### 11. Exponential Distribution:
Describes the time between events in a Poisson process (continuous analog of the Poisson distribution).

### 12. Gamma Distribution:
Generalizes the exponential distribution and is often used in reliability analysis.


### 13. Weibull Distribution: 
Commonly used in survival analysis to model time-to-failure data.

### 14. Log-Normal Distribution:
Used to model data that follows a log-normal pattern after taking the natural logarithm.

### 15 .Beta Distribution: 
Used to model random variables constrained to the interval [0, 1], such as probabilities.

### 16. Cauchy Distribution: 
Known for its heavy tails and lack of finite moments, which makes it sensitive to outliers.

### 17. Chi-Square Distribution: 
Arises in hypothesis testing and is the distribution of the sum of squared standard normal random variables.

### 18. Student's t-Distribution: 
Used in hypothesis testing for small sample sizes when the population standard deviation is unknown.

### 19. F-Distribution: 
Often used in analysis of variance (ANOVA) and regression analysis.

These are just some of the most commonly encountered probability distributions in statistics. There are many other specialized distributions that are used in various fields of study and for modeling different types of data. The choice of distribution depends on the nature of the data and the statistical problem at hand.
